{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to the Jupyter Notebook containing the review code for our first Advanced Workshop. This will have a/ll the important parts of the code we develop and relevant explanations. It also has some sources you can get some better explanations than mine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports for this workshop:\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "from PIL import Image\n",
    "from matplotlib.pyplot import imshow\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Classifers #\n",
    "\n",
    "   In this workshop we'll be taking a bottom up approach to Convolutional Neural Nets, starting with a basic example â€“ the linear classifier. The linear classifier is a function that takes our input vector to our prediction quantities, which we can compare to see what we've predicted. It's called a linear classifier because the prediction matrix is linear:\n",
    "\n",
    "<center>$Wx^T = p$ </center>\n",
    "\n",
    "where $W$ is our weight matrix, $x^T$ is a column vector, and $p$ is our prediction. We might also use\n",
    "\n",
    "<br>\n",
    "<center>$Wx^T + b = p$ </center>\n",
    "\n",
    "where $b$ is called the bias (making our classifier affine) but we'll call it linear anyway. For image prediction, because there isn't a matrix that can multiply another matrix to get a vector, we need to unravel our image into a vector. We can do that with this code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [4, 5, 6],\n",
       "       [7, 8, 9]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = np.array([[1,2,3],[4,5,6],[7,8,9]]) # Some arbitrary image matrix\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fimage = image.flatten()\n",
    "fimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.43597693, 0.08774387, 0.61858843, 0.69854032, 0.44922224,\n",
       "        0.49551985, 0.86731742, 0.85615986, 0.18641292],\n",
       "       [0.23813162, 0.9952018 , 0.78485486, 0.78924998, 0.04153802,\n",
       "        0.92858531, 0.52613748, 0.60629249, 0.3166069 ],\n",
       "       [0.56485564, 0.50237047, 0.52300527, 0.15454692, 0.53355925,\n",
       "        0.56355294, 0.49164918, 0.53387962, 0.08143612]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = np.random.rand(3,fimage.size) # some arbitrary classifier matrix, with 3 rows and 9 columns.\n",
    "classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = np.dot(classifier, fimage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which would be our prediction vector. We'd take the max of these as our prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = np.argmax(p)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try this with a real example. This code loads in the first MNIST image, a picture of a handwritten 0, and flattens it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = np.asarray(Image.open('data/train/000001-num0.png')) / 255\n",
    "im_flat = im.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's multiply it by a classifier (which is just a random matrix for now, since we haven't decided how to pick the weights of the classfier):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = np.random.rand(10,im_flat.size) / im_flat.size\n",
    "prediction = np.dot(classifier, im_flat)\n",
    "number = np.argmax(prediction, axis=0)\n",
    "number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously, since the weights of our classifier matrix are random, every time we try this, we'll get a different prediction. Now, we figure out how to \"train\" the weights of the classifier matrix. The general procedure of learning is:\n",
    "\n",
    "<img src=\"pic/machinelearning.jpeg\" style=\"width: 500px;\">\n",
    "\n",
    "The loss function takes our prediction and the actual labels, called \"ground-truth\" labels, to a single value which represents how good our predictions are. Generally, our loss function will return zero if they are the same, and some large value if they are very different. What is in between these two extremes can be chosen according to our preferences during learning: we might want to penalize certain types of weights in our network more, or penalize certain types of predictions less if we think they are leading us in the right direction. \n",
    "\n",
    "In this workshop, we'll use the cross-entropy loss function. The specifics of why this is chosen are not important, just know that this loss function is generally used for categorization problems.\n",
    "\n",
    "Essentially, we are dealing with an optimization problem in which we must minimize the loss by improving the weights in our matrix. We can solve this optimization problem with several methods, but a common method used in machine learning is gradient descent, which is what we'll use later for our convolutional neural nets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss Functions\n",
    "def CCEntropy(prediction, groundtruth):\n",
    "    return(-np.sum(groundtruth * np.log(prediction)))\n",
    "\n",
    "def L2Norm(prediction, groundtruth):\n",
    "    return(np.sum(np.sqrt(np.square(prediction) + np.square(groundtruth))))\n",
    "\n",
    "def softmax(prediction):\n",
    "    return(np.exp(prediction) / sum(np.exp(prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Loaded\n"
     ]
    }
   ],
   "source": [
    "# Data Loader\n",
    "def data():\n",
    "    images = []\n",
    "    groundtruths = []\n",
    "    for file in os.listdir(\"data/train/\"):\n",
    "        n = int(file[10])\n",
    "        images.append(np.asarray(Image.open(\"data/train/\" + file)) / 255)\n",
    "        groundtruths.append(np.asarray((n)*[0] + [1] + (1 - n)*[0])) #literally do not ever do this\n",
    "    print(\"Data Loaded\")\n",
    "    return(images, groundtruths)\n",
    "\n",
    "images, groundtruths = data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0xb180de940>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "imshow(images[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Training our linear classifier\n",
    "# Honestly, this thing is impossible to get to work. \n",
    "# I think my gradient formula is bad, but I've tried everything and either \n",
    "# my gradients explode or they go to zero real quick. \n",
    "# Maybe you can give this a try. \n",
    "# But this code gives an idea of the general training algorithm we would use. \n",
    "\n",
    "epoch_loss = []\n",
    "epochs = 10\n",
    "learningrate = 0.1\n",
    "\n",
    "W = (np.random.rand(2,28 * 28) - 0.5) * np.sqrt(6 / (28 * 28 + 2))\n",
    "b = np.zeros(2)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i, image in enumerate(images[1:2]):\n",
    "        \n",
    "        groundtruth = groundtruths[i]\n",
    "        \n",
    "        # Make prediction\n",
    "        prediction = np.dot(W, image.flatten()) + b\n",
    "        prediction = softmax(prediction)\n",
    "        \n",
    "        # Calculate Gradients\n",
    "        dy = 2 * (prediction - groundtruth)\n",
    "        dW = np.outer(dy, image.flatten())\n",
    "\n",
    "        # Update Predictor\n",
    "        W = W - learningrate * dW \n",
    "        b = b - learningrate * dy\n",
    "        #W = np.clip(W,-np.sqrt(6 / (28 * 28 + 2)),np.sqrt(6 / (28 * 28 + 2)))\n",
    "        \n",
    "        print(W)\n",
    "        print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Nets\n",
    "\n",
    "Here we're going to switch to Pytorch, a machine learning framework. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(1, 3, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = torch.nn.Conv2d(3, 10, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.fc1 = torch.nn.Linear(10 * 14 * 14, 64)\n",
    "        self.fc2 = torch.nn.Linear(64, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.double()\n",
    "        x = F.relu(self.conv2(F.relu(self.conv1(x)))) #convolve\n",
    "        x = self.pool(x) #pool\n",
    "        x = x.view(-1, 10 * 14 *14) #reshape\n",
    "        x = self.fc2(F.relu(self.fc1(x))) #classifier\n",
    "        return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Loaded\n"
     ]
    }
   ],
   "source": [
    "def data():\n",
    "    images = []\n",
    "    groundtruths = []\n",
    "    for file in os.listdir(\"data/train/\"):\n",
    "        n = int(file[10])\n",
    "        images.append(np.asarray(Image.open(\"data/train/\" + file)) / 255)\n",
    "        groundtruths.append(np.asarray((n)*[0] + [1] + (9 - n)*[0])) #literally do not ever do this\n",
    "    print(\"Data Loaded\")\n",
    "    return(images, groundtruths)\n",
    "images, groundtruths = data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 60000\n",
      "1000 / 60000\n",
      "2000 / 60000\n",
      "3000 / 60000\n",
      "4000 / 60000\n",
      "5000 / 60000\n",
      "6000 / 60000\n",
      "7000 / 60000\n",
      "8000 / 60000\n",
      "9000 / 60000\n",
      "10000 / 60000\n",
      "11000 / 60000\n",
      "12000 / 60000\n",
      "13000 / 60000\n",
      "14000 / 60000\n",
      "15000 / 60000\n",
      "16000 / 60000\n",
      "17000 / 60000\n",
      "18000 / 60000\n",
      "19000 / 60000\n",
      "20000 / 60000\n",
      "21000 / 60000\n",
      "22000 / 60000\n",
      "23000 / 60000\n",
      "24000 / 60000\n",
      "25000 / 60000\n",
      "26000 / 60000\n",
      "27000 / 60000\n",
      "28000 / 60000\n",
      "29000 / 60000\n",
      "30000 / 60000\n",
      "31000 / 60000\n",
      "32000 / 60000\n",
      "33000 / 60000\n",
      "34000 / 60000\n",
      "35000 / 60000\n",
      "36000 / 60000\n",
      "37000 / 60000\n",
      "38000 / 60000\n",
      "39000 / 60000\n",
      "40000 / 60000\n",
      "41000 / 60000\n",
      "42000 / 60000\n",
      "43000 / 60000\n",
      "44000 / 60000\n",
      "45000 / 60000\n",
      "46000 / 60000\n",
      "47000 / 60000\n",
      "48000 / 60000\n",
      "49000 / 60000\n",
      "50000 / 60000\n",
      "51000 / 60000\n",
      "52000 / 60000\n",
      "53000 / 60000\n",
      "54000 / 60000\n",
      "55000 / 60000\n",
      "56000 / 60000\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.01\n",
    "n_epochs = 3\n",
    "net = CNN().double()\n",
    "loss = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "for epoch in range(n_epochs):        \n",
    "        for i in range(len(images)):\n",
    "            inputs, labels = Variable(torch.from_numpy(images[i])), Variable(torch.from_numpy(groundtruths[i]))\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs.unsqueeze(0).unsqueeze(0))\n",
    "            loss_size = loss(outputs, labels.unsqueeze(0).double())\n",
    "            loss_size.backward()\n",
    "            if i % 1000 == 0:\n",
    "                print(str(i) + \" / \" + str(len(images)))\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()\n",
    "prediction = net(torch.from_numpy(images[5]).unsqueeze(0).unsqueeze(0).double())\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 1 0 0]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "imshow(images[10])\n",
    "print(groundtruths[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
